{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee87d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23b1679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "#userdata.get('secretName')\n",
    "os.environ['LANGCHAIN_API_KEY'] = userdata.get('LENGSMITH_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT'] = userdata.get('LANGSMITH_PROJECT')\n",
    "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = userdata.get('LANGSMITH_ENDPOINT')\n",
    "os.environ['LANGCHAIN_TRACING'] = userdata.get('LANGSMITH_TRACING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44675bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0235c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d158938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /content/drive/MyDrive/디스부 특강/corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868638b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import csv_loader\n",
    "\n",
    "test = csv_loader.CSVLoader(file_path='./test.csv')\n",
    "train = csv_loader.CSVLoader(file_path='./train.csv')\n",
    "\n",
    "doc = test.load() + train.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3490c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7f3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt, Kkma\n",
    "\n",
    "okt = Okt()\n",
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3acfb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_okt(text):\n",
    "  tokens = [token for token in okt.morphs(text)]\n",
    "  return len(tokens)\n",
    "\n",
    "def okt_tokenize(text):\n",
    "  return [token for token in okt.morphs(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e747cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_kkma(text):\n",
    "  tokens = [token for token in kkma.morphs(text)]\n",
    "  return len(tokens)\n",
    "\n",
    "def kkma_tokenize(text):\n",
    "  return [token for token in kkma.morphs(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7241827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['\\n\\n', '\\n', ' '],   # 1000토큰을 넘지않고 엔터를 기준으로 split\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len_okt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb34459",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29b3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e203570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"jhgan/ko-sbert-nli\"\n",
    "# model_kwargs = {'device': 'cpu'}  # cpu\n",
    "model_kwargs = {'device': 'cuda'}  # gpu\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf_embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be34678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass, os\n",
    "\n",
    "if not userdata.get('OPENAI_API_KEY'):\n",
    "  os.environ['OPENAI_API_KEY'] = getpass.getpass('Enter API Key for OpenAI: ')\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "openai_embedding_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd766273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd /content/drive/MyDrive/디스부 특강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a305ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = './chroma_docs_db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3494bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0650be46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb077a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(documents=texts, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe8348",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d6614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"너는 손자같이 말하는 인공지능이다.\n",
    "공손하고 따뜻한 말투이어야 한다.\n",
    "사용자는 할머니라는 사실을 꼭 적용해야 한다.\n",
    "대화 흐름에 맞는 대답하기 쉬운 질문 하나만 생성한다.\n",
    "\n",
    "질문은 반드시 한국어로 한 문장만 생성하고,\n",
    "너무 길거나 복잡하지 않게 해야 한다.\n",
    "\n",
    "\n",
    "#Previous Chat History:\n",
    "{chat_history}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Context:\n",
    "{context}\n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba080d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# 단계 8: 체인(Chain) 생성\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"chat_history\": itemgetter(\"chat_history\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcff0cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션 기록을 저장할 딕셔너리\n",
    "store = {}\n",
    "\n",
    "\n",
    "# 세션 ID를 기반으로 세션 기록을 가져오는 함수\n",
    "def get_session_history(session_ids):\n",
    "    print(f\"[대화 세션ID]: {session_ids}\")\n",
    "    if session_ids not in store:  # 세션 ID가 store에 없는 경우\n",
    "        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환\n",
    "\n",
    "\n",
    "# 대화를 기록하는 RAG 체인 생성\n",
    "rag_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,  # 세션 기록을 가져오는 함수\n",
    "    input_messages_key=\"question\",  # 사용자의 질문이 템플릿 변수에 들어갈 key\n",
    "    history_messages_key=\"chat_history\",  # 기록 메시지의 키\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = 'gpt-4o-mini',\n",
    "    temperature=0.3,\n",
    "    streaming=True,   # 한 글자씩 보여줌\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5498aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(doc):\n",
    "  # test = \"\\n\\n\".join(document.page_content for document in docs)\n",
    "  # print(test)\n",
    "  return \"\\n\\n\".join(document.page_content for document in doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "rag_with_history.invoke(\n",
    "    # 질문 입력\n",
    "    {\"question\": \"내가 오늘 뭐 했다고 했지?\"},\n",
    "    # 세션 ID 기준으로 대화를 기록합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
